{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/09/25 11:15:30 WARN Utils: Your hostname, LAPTOP-MMSL4U2D resolves to a loopback address: 127.0.1.1; using 172.18.73.152 instead (on interface eth0)\n",
      "24/09/25 11:15:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/25 11:15:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------------+--------------------+--------------+--------------------+--------------------+-----------+-----+--------+------+--------------------------+--------------------------+--------------+--------------------+------------------+------------------+----------------------+--------------------+------------+--------------------+--------------------------+--------------------+--------+\n",
      "|user_id|merchant_abn|      dollar_value|            order_id|order_datetime|       merchant_name|                tags|consumer_id|state|postcode|gender|consumer_fraud_probability|merchant_fraud_probability| LOCALITY_NAME|       list_SA2_CODE|          list_ERP|  list_num_earners|list_total_income_($M)|    list_mean_income|postcode_ERP|postcode_num_earners|postcode_total_income_($M)|postcode_mean_income|is_fraud|\n",
      "+-------+------------+------------------+--------------------+--------------+--------------------+--------------------+-----------+-----+--------+------+--------------------------+--------------------------+--------------+--------------------+------------------+------------------+----------------------+--------------------+------------+--------------------+--------------------------+--------------------+--------+\n",
      "|  14935| 43186523025|19.157007083987565|b184da75-2473-42c...|    2021-11-12|Lorem Ipsum Sodal...|([florists suppli...|    1059280|  QLD|    4563|  Male|                       0.0|                       0.0|BLACK MOUNTAIN|[319031514, 31608...|    [21774, 25578]|    [10606, 14487]|        [510.4, 798.8]|  [48127.0, 55139.0]|       47352|               25093|        1309.1999999999998|   52173.91304347825|   false|\n",
      "|      2| 57405729081| 220.5325772234713|342ab194-e5e9-4fa...|    2021-11-12|   Augue Corporation|[[watch, clock, a...|     179208|  NSW|    2782|Female|                       0.0|                       0.0|    HAZELBROOK|         [124011455]|            [6376]|            [3601]|               [226.3]|           [62840.0]|        6376|                3601|                     226.3|             62840.0|   false|\n",
      "|  14936| 60956456424|115.18299907550252|28a3c548-2f6c-4d1...|    2021-11-12|Ultricies Digniss...|([gift, card, Nov...|     986886|   SA|    5157|Female|                       0.0|                       0.0|     ASHBOURNE|[407011147, 40304...|[8376, 2824, 7111]|[4446, 1754, 4110]|  [234.3, 115.0, 23...|[52688.0, 65560.0...|       18311|               10310|                     586.0|    56838.0213385063|   false|\n",
      "|      5| 64203420245|20.905080869875956|64614527-4be7-4f6...|    2021-11-12|  Pede Nonummy Corp.|((tent and awning...|     712975|   WA|    6355|Female|                       0.0|                       0.0|     DUNN ROCK|         [509031247]|            [4355]|            [2915]|               [158.9]|           [54507.0]|        4355|                2915|                     158.9|             54507.0|   false|\n",
      "|  14936| 72738688428|194.98940026275412|0bde82ed-03f2-44b...|    2021-11-12|  Donec Tempor Corp.|((books, periodic...|     986886|   SA|    5157|Female|                       0.0|                       0.0|     ASHBOURNE|[407011147, 40304...|[8376, 2824, 7111]|[4446, 1754, 4110]|  [234.3, 115.0, 23...|[52688.0, 65560.0...|       18311|               10310|                     586.0|    56838.0213385063|   false|\n",
      "+-------+------------+------------------+--------------------+--------------+--------------------+--------------------+-----------+-----+--------+------+--------------------------+--------------------------+--------------+--------------------+------------------+------------------+----------------------+--------------------+------------+--------------------+--------------------------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans_final_sdf = spark.read.parquet('../data/merged/merged_transactions_with_outliers.parquet')\n",
    "trans_final_sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------------+------------------------------------+--------------+------------------------------+-------------------------------------------------------------------------+-----------+-----+--------+------+--------------------------+--------------------------+--------------+---------------------------------+------------------+------------------+----------------------+---------------------------+------------+--------------------+--------------------------+--------------------+--------+-------------------------------------------------------------------------+\n",
      "|user_id|merchant_abn|dollar_value      |order_id                            |order_datetime|merchant_name                 |tags                                                                     |consumer_id|state|postcode|gender|consumer_fraud_probability|merchant_fraud_probability|LOCALITY_NAME |list_SA2_CODE                    |list_ERP          |list_num_earners  |list_total_income_($M)|list_mean_income           |postcode_ERP|postcode_num_earners|postcode_total_income_($M)|postcode_mean_income|is_fraud|fixed_tags                                                               |\n",
      "+-------+------------+------------------+------------------------------------+--------------+------------------------------+-------------------------------------------------------------------------+-----------+-----+--------+------+--------------------------+--------------------------+--------------+---------------------------------+------------------+------------------+----------------------+---------------------------+------------+--------------------+--------------------------+--------------------+--------+-------------------------------------------------------------------------+\n",
      "|14935  |43186523025 |19.157007083987565|b184da75-2473-42c1-9109-53e1d4e9400f|2021-11-12    |Lorem Ipsum Sodales Industries|([florists supplies, nurSery stock, and flowers], [b], [take rate: 4.47])|1059280    |QLD  |4563    |Male  |0.0                       |0.0                       |BLACK MOUNTAIN|[319031514, 316081549]           |[21774, 25578]    |[10606, 14487]    |[510.4, 798.8]        |[48127.0, 55139.0]         |47352       |25093               |1309.1999999999998        |52173.91304347825   |false   |[[florists supplies, nursery stock, and flowers], [b], [take rate: 4.47]]|\n",
      "|2      |57405729081 |220.5325772234713 |342ab194-e5e9-4fa9-b1cf-52e76559b0dc|2021-11-12    |Augue Corporation             |[[watch, clock, and jewelry repair shops], [c], [take rate: 2.22]]       |179208     |NSW  |2782    |Female|0.0                       |0.0                       |HAZELBROOK    |[124011455]                      |[6376]            |[3601]            |[226.3]               |[62840.0]                  |6376        |3601                |226.3                     |62840.0             |false   |[[watch, clock, and jewelry repair shops], [c], [take rate: 2.22]]       |\n",
      "|14936  |60956456424 |115.18299907550252|28a3c548-2f6c-4d1d-b705-8b37b52c5f28|2021-11-12    |Ultricies Dignissim LLP       |([gift, card, Novelty, and souvenir shops], [b], [take rate: 4.69])      |986886     |SA   |5157    |Female|0.0                       |0.0                       |ASHBOURNE     |[407011147, 403041075, 401021008]|[8376, 2824, 7111]|[4446, 1754, 4110]|[234.3, 115.0, 236.7] |[52688.0, 65560.0, 57603.0]|18311       |10310               |586.0                     |56838.0213385063    |false   |[[gift, card, novelty, and souvenir shops], [b], [take rate: 4.69]]      |\n",
      "|5      |64203420245 |20.905080869875956|64614527-4be7-4f61-9af8-8f7a21a6a927|2021-11-12    |Pede Nonummy Corp.            |((tent and awning shops), (c), (take rate: 2.86))                        |712975     |WA   |6355    |Female|0.0                       |0.0                       |DUNN ROCK     |[509031247]                      |[4355]            |[2915]            |[158.9]               |[54507.0]                  |4355        |2915                |158.9                     |54507.0             |false   |[[tent and awning shops], [c], [take rate: 2.86]]                        |\n",
      "|14936  |72738688428 |194.98940026275412|0bde82ed-03f2-44b7-b046-7dc17954854a|2021-11-12    |Donec Tempor Corp.            |((books, periodicals, and newspapers), (a), (take rate: 5.67))           |986886     |SA   |5157    |Female|0.0                       |0.0                       |ASHBOURNE     |[407011147, 403041075, 401021008]|[8376, 2824, 7111]|[4446, 1754, 4110]|[234.3, 115.0, 236.7] |[52688.0, 65560.0, 57603.0]|18311       |10310               |586.0                     |56838.0213385063    |false   |[[books, periodicals, and newspapers], [a], [take rate: 5.67]]           |\n",
      "+-------+------------+------------------+------------------------------------+--------------+------------------------------+-------------------------------------------------------------------------+-----------+-----+--------+------+--------------------------+--------------------------+--------------+---------------------------------+------------------+------------------+----------------------+---------------------------+------------+--------------------+--------------------------+--------------------+--------+-------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Function to convert to string of list\n",
    "import re\n",
    "def process_string(input_string):\n",
    "    # Replace () with []\n",
    "    input_string = input_string.replace('(', '[')\n",
    "    input_string = input_string.replace(')', ']')\n",
    "\n",
    "    # Use regex to split by outer brackets and commas\n",
    "    lists = re.findall(r'\\[([^\\[\\]]+)\\]', input_string)\n",
    "\n",
    "    # Further split elements within the lists based on commas, while stripping whitespace\n",
    "    result = [list(map(str.strip, item.split(','))) for item in lists]\n",
    "\n",
    "    # Clean up each item by stripping leading/trailing whitespace and correcting case\n",
    "    for sublist in result:\n",
    "        for i in range(len(sublist)):\n",
    "            sublist[i] = sublist[i].strip().lower()\n",
    "\n",
    "    return result\n",
    "# Register UDF in PySpark\n",
    "process_string_udf = F.udf(process_string)\n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "result_df = trans_final_sdf.withColumn(\"fixed_tags\", process_string_udf(F.col(\"tags\")))\n",
    "\n",
    "# Show the result\n",
    "result_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- merchant_abn: long (nullable = true)\n",
      " |-- dollar_value: double (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_datetime: date (nullable = true)\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- consumer_id: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postcode: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- consumer_fraud_probability: double (nullable = true)\n",
      " |-- merchant_fraud_probability: double (nullable = true)\n",
      " |-- LOCALITY_NAME: string (nullable = true)\n",
      " |-- list_SA2_CODE: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- list_ERP: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- list_num_earners: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- list_total_income_($M): array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- list_mean_income: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- postcode_ERP: integer (nullable = true)\n",
      " |-- postcode_num_earners: integer (nullable = true)\n",
      " |-- postcode_total_income_($M): double (nullable = true)\n",
      " |-- postcode_mean_income: double (nullable = true)\n",
      " |-- is_fraud: boolean (nullable = true)\n",
      " |-- fixed_tags: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o177.cast.\n: scala.MatchError: array (of class java.lang.String)\n\tat org.apache.spark.sql.errors.QueryParsingErrors$.nestedTypeMissingElementTypeError(QueryParsingErrors.scala:286)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.$anonfun$visitPrimitiveDataType$1(DataTypeAstBuilder.scala:88)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils$.withOrigin(SparkParserUtils.scala:156)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.visitPrimitiveDataType(DataTypeAstBuilder.scala:60)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.visitPrimitiveDataType(DataTypeAstBuilder.scala:32)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimitiveDataTypeContext.accept(SqlBaseParser.java:21753)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:34)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleDataType$1(AstBuilder.scala:145)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleDataType(AstBuilder.scala:145)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.$anonfun$parseDataType$1(parsers.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:80)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parseDataType(parsers.scala:40)\n\tat org.apache.spark.sql.Column.cast(Column.scala:1190)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result_df \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_fixed_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfixed_tags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/column.py:1204\u001b[0m, in \u001b[0;36mColumn.cast\u001b[0;34m(self, dataType)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;124;03mCasts the column into type ``dataType``.\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;124;03m[Row(ages='2'), Row(ages='5')]\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataType, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1204\u001b[0m     jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataType\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataType, DataType):\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o177.cast.\n: scala.MatchError: array (of class java.lang.String)\n\tat org.apache.spark.sql.errors.QueryParsingErrors$.nestedTypeMissingElementTypeError(QueryParsingErrors.scala:286)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.$anonfun$visitPrimitiveDataType$1(DataTypeAstBuilder.scala:88)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils$.withOrigin(SparkParserUtils.scala:156)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.visitPrimitiveDataType(DataTypeAstBuilder.scala:60)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.visitPrimitiveDataType(DataTypeAstBuilder.scala:32)\n\tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$PrimitiveDataTypeContext.accept(SqlBaseParser.java:21753)\n\tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:34)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleDataType$1(AstBuilder.scala:145)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n\tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n\tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n\tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleDataType(AstBuilder.scala:145)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.$anonfun$parseDataType$1(parsers.scala:41)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:80)\n\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parseDataType(parsers.scala:40)\n\tat org.apache.spark.sql.Column.cast(Column.scala:1190)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "result_df = result_df.withColumn(\"list_fixed_tags\", F.col(\"fixed_tags\").cast(\"array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[INVALID_EXTRACT_BASE_FIELD_TYPE] Can't extract a value from \"fixed_tags\". Need a complex type [STRUCT, ARRAY, MAP] but got \"STRING\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mresult_df\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m----> 2\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfixed_tags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\\\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevenue_bands\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfixed_tags\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\\\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtake_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfixed_tags\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      5\u001b[0m result_df\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m, truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:5174\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5171\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5172\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   5173\u001b[0m     )\n\u001b[0;32m-> 5174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [INVALID_EXTRACT_BASE_FIELD_TYPE] Can't extract a value from \"fixed_tags\". Need a complex type [STRUCT, ARRAY, MAP] but got \"STRING\"."
     ]
    }
   ],
   "source": [
    "result_df = result_df \\\n",
    "        .withColumn('description', F.col('fixed_tags')[0])\\\n",
    "        .withColumn('revenue_bands', F.col('fixed_tags')[1])\\\n",
    "        .withColumn('take_rate', F.col('fixed_tags')[2])\n",
    "result_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df.write.mode(\"overwrite\").parquet(\"../data/merged/merged_transactions_with_tags.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
